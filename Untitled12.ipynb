{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User authenticated!\n"
     ]
    }
   ],
   "source": [
    "%authenticate 26 -u dev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.exceptions.HTTPError'>\n",
      "('500 Server Error: Internal Server Error for url: https://hpecp-47.hpecplocal:8998/sessions/5/statements',)\n",
      "500 Server Error: Internal Server Error for url: https://hpecp-47.hpecplocal:8998/sessions/5/statements\n"
     ]
    }
   ],
   "source": [
    "%%train 26 --sparkr\n",
    "# Load training data\n",
    "data <- list(list(0, 0, 4.0), list(0, 1, 2.0), list(1, 1, 3.0),\n",
    "             list(1, 2, 4.0), list(2, 1, 1.0), list(2, 2, 5.0))\n",
    "df <- createDataFrame(data, c(\"userId\", \"movieId\", \"rating\"))\n",
    "training <- df\n",
    "test <- df\n",
    "\n",
    "# Fit a recommendation model using ALS with spark.als\n",
    "model <- spark.als(training, maxIter = 5, regParam = 0.01, userCol = \"userId\",\n",
    "                   itemCol = \"movieId\", ratingCol = \"rating\")\n",
    "\n",
    "# Model summary\n",
    "summary(model)\n",
    "\n",
    "# Prediction\n",
    "predictions <- predict(model, test)\n",
    "head(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import seaborn\n",
    "import statsmodels\n",
    "import sklearn\n",
    "import bokeh\n",
    "import hyperopt\n",
    "import lightgbm\n",
    "import torch\n",
    "import torchvision\n",
    "import theano\n",
    "import xgboost\n",
    "import plotly\n",
    "import tabulate\n",
    "import sklearn\n",
    "import sudospawner\n",
    "import gast\n",
    "import scipy\n",
    "import matplotlib\n",
    "import pandas\n",
    "import keras\n",
    "import numpy\n",
    "import tensorflow_metadata\n",
    "import tornado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.exceptions.HTTPError'>\n",
      "('500 Server Error: Internal Server Error for url: https://hpecp-47.hpecplocal:8998/sessions/6/statements',)\n",
      "500 Server Error: Internal Server Error for url: https://hpecp-47.hpecplocal:8998/sessions/6/statements\n"
     ]
    }
   ],
   "source": [
    "%%train 26 --pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "import sys\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "def loadMovieNames(lines):\n",
    "    movieNames = {}\n",
    "    for ids in lines.collect():\n",
    "        fields = ids.split('|')\n",
    "        movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "def parseInput(line):\n",
    "    fields = line.split()\n",
    "    return Row(movieID = int(fields[1]), rating = float(fields[2]))\n",
    "\n",
    "\n",
    "# Create a SparkSession (the config bit is only for Windows!)\n",
    "spark = SparkSession.builder.appName(\"MovieRecommentation\").getOrCreate()\n",
    "#rlocation= \"file:///bd-fs-mnt/TenantShare/repo/data/ml-100k\"\n",
    "rlocation= \"file:///bd-fs-mnt/project_repo/data/ml-100k\"\n",
    "\n",
    "# Load up our movie ID -> name dictionary\n",
    "mnLines = spark.sparkContext.textFile(rlocation+\"/u.item\")\n",
    "movieNames = loadMovieNames(mnLines)\n",
    "\n",
    "# Get the raw data\n",
    "lines = spark.sparkContext.textFile(rlocation+\"/u.data\")\n",
    "ratings = lines.map(lambda l: l.split()).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2]))).cache()\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "print(\"\\nTraining recommendation model...\")\n",
    "rank = 10\n",
    "# Lowered numIterations to ensure it works on lower-end systems\n",
    "numIterations = 6\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "modelLoc = \"file:///bd-fs-mnt/project_repo/models/movierecommendation\"\n",
    "model.save(spark.sparkContext,modelLoc)\n",
    "\n",
    "userID = 2\n",
    "\n",
    "print(\"\\nRatings for user ID \" + str(userID) + \":\")\n",
    "userRatings = ratings.filter(lambda l: l[0] == userID)\n",
    "for rating in userRatings.collect():\n",
    "    print (movieNames[int(rating[1])] + \": \" + str(rating[2]))\n",
    "\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "recommendations = model.recommendProducts(userID, 10)\n",
    "for recommendation in recommendations:\n",
    "    print (movieNames[int(recommendation[1])] + \\\n",
    "        \" score \" + str(recommendation[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
